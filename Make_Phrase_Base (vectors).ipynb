{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from unidecode import unidecode\n",
    "\n",
    "def transliterate_text(text: str) -> str:\n",
    "    f_str = unidecode(text)\n",
    "    return \"\".join([ch for ch in f_str.lower() if ch.isalpha()])\n",
    "\n",
    "def read_text_file(fileName: str) -> str:\n",
    "    f = open(fileName, \"r\", encoding=\"utf-8\")\n",
    "    f_str = f.read()\n",
    "    f.close()\n",
    "    return transliterate_text(f_str)\n",
    "\n",
    "def num_to_bit_indices(num: int, shifts=8) -> tuple:\n",
    "    return tuple(bit for bit in range(shifts) if num & (1 << bit))\n",
    "\n",
    "def gen_unique_bit_marks(mark_count, bit_count=8, active_bits=4) -> list:\n",
    "    \n",
    "    def gen_mark() -> tuple:\n",
    "        mark = np.random.choice(bit_count, active_bits, replace=False)\n",
    "        return tuple(sorted(mark))\n",
    "    \n",
    "    marks = set()\n",
    "    for i in range(mark_count):\n",
    "        brake = 1000\n",
    "        while True:\n",
    "            mark = gen_mark()\n",
    "            if mark not in marks:\n",
    "                marks.add(mark)\n",
    "                break\n",
    "            else:\n",
    "                brake -= 1\n",
    "                if brake == 0:\n",
    "                    raise Exception(\"attempt limit overflow\")\n",
    "    return list(marks)\n",
    "\n",
    "\n",
    "def letter_to_note(letter):\n",
    "    return ord(letter.lower()) - ord('a')\n",
    "\n",
    "def phrase_transpositions(phrase: list, pos: int, notation_count: int) -> list: \n",
    "    return [[(phrase[note], (i + shift) % notation_count) \n",
    "             for note, i in enumerate(range(pos, pos + len(phrase)))]\n",
    "            for shift in range(notation_count)]\n",
    "\n",
    "def text_to_noted_phrases(text: str, phrase_len: int, notation_count: int) -> list:\n",
    "    note_phrases = []\n",
    "    for i in range(0, len(text) - phrase_len):\n",
    "        phrase = [letter_to_note(letter) for letter in text[i:i + phrase_len]]\n",
    "        note_phrases.extend(phrase_transpositions(phrase, pos=i, notation_count=notation_count))\n",
    "    return note_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[(20, 0), (2, 1), (7, 2), (4, 3), (13, 4)],\n",
       " [(20, 1), (2, 2), (7, 3), (4, 4), (13, 0)],\n",
       " [(20, 2), (2, 3), (7, 4), (4, 0), (13, 1)],\n",
       " [(20, 3), (2, 4), (7, 0), (4, 1), (13, 2)],\n",
       " [(20, 4), (2, 0), (7, 1), (4, 2), (13, 3)],\n",
       " [(2, 1), (7, 2), (4, 3), (13, 4), (8, 0)],\n",
       " [(2, 2), (7, 3), (4, 4), (13, 0), (8, 1)],\n",
       " [(2, 3), (7, 4), (4, 0), (13, 1), (8, 2)],\n",
       " [(2, 4), (7, 0), (4, 1), (13, 2), (8, 3)],\n",
       " [(2, 0), (7, 1), (4, 2), (13, 3), (8, 4)],\n",
       " [(7, 2), (4, 3), (13, 4), (8, 0), (19, 1)],\n",
       " [(7, 3), (4, 4), (13, 0), (8, 1), (19, 2)],\n",
       " [(7, 4), (4, 0), (13, 1), (8, 2), (19, 3)],\n",
       " [(7, 0), (4, 1), (13, 2), (8, 3), (19, 4)],\n",
       " [(7, 1), (4, 2), (13, 3), (8, 4), (19, 0)],\n",
       " [(4, 3), (13, 4), (8, 0), (19, 1), (4, 2)],\n",
       " [(4, 4), (13, 0), (8, 1), (19, 2), (4, 3)],\n",
       " [(4, 0), (13, 1), (8, 2), (19, 3), (4, 4)],\n",
       " [(4, 1), (13, 2), (8, 3), (19, 4), (4, 0)],\n",
       " [(4, 2), (13, 3), (8, 4), (19, 0), (4, 1)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'ucheniteotkrilicherazlikatasedlzhinamikrobitekoitosekriiatvnaskhorataspodeliatsamoedniisshchimikrobiavsichkiostanalisastrogoindividualni'\n",
    "noted_phrases = text_to_noted_phrases(text, phrase_len=5, notation_count=5)\n",
    "print(len(text), len(noted_phrases))\n",
    "noted_phrases[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((0, 1), [(20, 0), (2, 1), (7, 2), (4, 3), (13, 4)]),\n",
       " ((0, 1), [(20, 1), (2, 2), (7, 3), (4, 4), (13, 5)]),\n",
       " ((0, 1), [(20, 2), (2, 3), (7, 4), (4, 5), (13, 6)]),\n",
       " ((0, 1), [(20, 3), (2, 4), (7, 5), (4, 6), (13, 7)]),\n",
       " ((0, 1), [(20, 4), (2, 5), (7, 6), (4, 7), (13, 8)]),\n",
       " ((0, 1), [(20, 5), (2, 6), (7, 7), (4, 8), (13, 9)]),\n",
       " ((0, 1), [(20, 6), (2, 7), (7, 8), (4, 9), (13, 0)]),\n",
       " ((0, 1), [(20, 7), (2, 8), (7, 9), (4, 0), (13, 1)]),\n",
       " ((0, 1), [(20, 8), (2, 9), (7, 0), (4, 1), (13, 2)]),\n",
       " ((0, 1), [(20, 9), (2, 0), (7, 1), (4, 2), (13, 3)]),\n",
       " ((0, 1), [(2, 1), (7, 2), (4, 3), (13, 4), (8, 5)]),\n",
       " ((0, 1), [(2, 2), (7, 3), (4, 4), (13, 5), (8, 6)]),\n",
       " ((0, 1), [(2, 3), (7, 4), (4, 5), (13, 6), (8, 7)]),\n",
       " ((0, 1), [(2, 4), (7, 5), (4, 6), (13, 7), (8, 8)]),\n",
       " ((0, 1), [(2, 5), (7, 6), (4, 7), (13, 8), (8, 9)]),\n",
       " ((0, 1), [(2, 6), (7, 7), (4, 8), (13, 9), (8, 0)]),\n",
       " ((0, 1), [(2, 7), (7, 8), (4, 9), (13, 0), (8, 1)]),\n",
       " ((0, 1), [(2, 8), (7, 9), (4, 0), (13, 1), (8, 2)]),\n",
       " ((0, 1), [(2, 9), (7, 0), (4, 1), (13, 2), (8, 3)]),\n",
       " ((0, 1), [(2, 0), (7, 1), (4, 2), (13, 3), (8, 4)])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = (0, 1)\n",
    "labeled_note_phrases = [(label, noted_phrase) for noted_phrase in noted_phrases]\n",
    "labeled_note_phrases[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make phrase_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_text_base() -> dict:\n",
    "    texts_dir = './data/texts/'\n",
    "    file_names = {\n",
    "        'bel': 'text_bel.txt',\n",
    "        'blg': 'text_blg.txt',\n",
    "        'eng': 'text_eng.txt',\n",
    "        'epo': 'text_epo.txt',\n",
    "        'jbo': 'text_jbo.txt',\n",
    "        'pol': 'text_pol.txt',\n",
    "        'rus': 'text_rus.txt',\n",
    "        'ukr': 'text_ukr.txt'\n",
    "    }\n",
    "    text_base = {}\n",
    "    for key, file_name in file_names.items():\n",
    "        text_base[key] = read_text_file(texts_dir + file_name)\n",
    "    return text_base \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_base = load_text_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_monotone_text_base():\n",
    "    letters = 'abcdefghklmnopst'\n",
    "    text_len = 10000\n",
    "    text_base = {}\n",
    "    for letter in letters:\n",
    "        text_base[letter * 3] = letter * text_len\n",
    "    return text_base    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_base = gen_monotone_text_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bel (0,)\n",
      "blg (1,)\n",
      "eng (2,)\n",
      "epo (3,)\n",
      "jbo (4,)\n",
      "pol (5,)\n",
      "rus (6,)\n",
      "ukr (7,)\n"
     ]
    }
   ],
   "source": [
    "phrase_base = {}\n",
    "marks_dict = {}\n",
    "# bit_marks = gen_unique_bit_marks(mark_count=len(text_base.keys())) # random cross-bit code\n",
    "bit_marks = [(i,) for i in range(len(text_base.keys()))] # one-shot code\n",
    "for i, key in enumerate(text_base.keys()):\n",
    "    bit_key = bit_marks[i]\n",
    "    marks_dict[bit_key] = key\n",
    "    noted_phrases = text_to_noted_phrases(text_base[key], phrase_len=5, notation_count=5)\n",
    "    phrase_base[bit_key] = noted_phrases\n",
    "    print(key, bit_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1428208"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase_base[bit_marks[1]].__sizeof__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25223"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_base['ukr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1958320"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(phrase_base[key]) for key in phrase_base.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load-Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_phrase_base(file_name: str, phrase_base: dict, marks: dict):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        data = {\n",
    "            'marks': marks, \n",
    "            'phrase_base': phrase_base\n",
    "        }\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def load_phrase_base(file_name: str) -> (dict, list):\n",
    "    with open(file_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        phrase_base = data.get('phrase_base', {})\n",
    "        marks = data.get('marks', {})\n",
    "        return phrase_base, marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = './data/texts/phrase_base.pickle'\n",
    "# file = './data/texts/monotone_base.pickle'\n",
    "save_phrase_base(file, phrase_base, marks_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phrase_base_loaded, marks_loaded = load_phrase_base(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(0, 3, 5, 7): 'bel', (0, 5, 6, 7): 'blg', (0, 1, 4, 6): 'eng', (0, 1, 3, 4): 'epo', (2, 3, 4, 7): 'jbo', (0, 3, 5, 6): 'pol', (0, 2, 4, 5): 'rus', (1, 4, 5, 6): 'ukr'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 3, 5, 7),\n",
       " (0, 5, 6, 7),\n",
       " (0, 1, 4, 6),\n",
       " (0, 1, 3, 4),\n",
       " (2, 3, 4, 7),\n",
       " (0, 3, 5, 6),\n",
       " (0, 2, 4, 5),\n",
       " (1, 4, 5, 6)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(marks_loaded)\n",
    "list(phrase_base_loaded.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make test phrase list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_noted_phrases(file_name: str, noted_phrases: list):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(noted_phrases, f)\n",
    "\n",
    "def load_noted_phrases(file_name: str) -> list:\n",
    "    with open(file_name, 'rb') as f:\n",
    "        noted_phrases = pickle.load(f)\n",
    "        return noted_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_text = read_text_file('./data/texts/tst_bel.txt')\n",
    "tst_noted_phrases = text_to_noted_phrases(tst_text, phrase_len=5, notation_count=5)\n",
    "save_noted_phrases('./data/texts/tst_bel.pickle', tst_noted_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_text = read_text_file('./data/texts/tst_rus.txt')\n",
    "tst_noted_phrases = text_to_noted_phrases(tst_text, phrase_len=5, notation_count=5)\n",
    "save_noted_phrases('./data/texts/tst_rus.pickle', tst_noted_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_text = read_text_file('./data/texts/tst_eng.txt')\n",
    "tst_noted_phrases = text_to_noted_phrases(tst_text, phrase_len=5, notation_count=5)\n",
    "save_noted_phrases('./data/texts/tst_eng.pickle', tst_noted_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_text = read_text_file('./data/texts/tst_ukr.txt')\n",
    "tst_noted_phrases = text_to_noted_phrases(tst_text, phrase_len=5, notation_count=5)\n",
    "save_noted_phrases('./data/texts/tst_ukr.pickle', tst_noted_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_text = read_text_file('./data/texts/tst_blg.txt')\n",
    "tst_noted_phrases = text_to_noted_phrases(tst_text, phrase_len=5, notation_count=5)\n",
    "save_noted_phrases('./data/texts/tst_blg.pickle', tst_noted_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_text = read_text_file('./data/texts/tst_jbo.txt')\n",
    "tst_noted_phrases = text_to_noted_phrases(tst_text, phrase_len=5, notation_count=5)\n",
    "save_noted_phrases('./data/texts/tst_jbo.pickle', tst_noted_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_text = read_text_file('./data/texts/tst_pol.txt')\n",
    "tst_noted_phrases = text_to_noted_phrases(tst_text, phrase_len=5, notation_count=5)\n",
    "save_noted_phrases('./data/texts/tst_pol.pickle', tst_noted_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst_text = read_text_file('./data/texts/tst_epo.txt')\n",
    "tst_noted_phrases = text_to_noted_phrases(tst_text, phrase_len=5, notation_count=5)\n",
    "save_noted_phrases('./data/texts/tst_epo.pickle', tst_noted_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3210"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tst_noted_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letters = 'abcdefghklmnopst'\n",
    "for letter in letters:\n",
    "    tst_noted_phrases = text_to_noted_phrases(letter * 100, phrase_len=5, notation_count=5)\n",
    "    save_noted_phrases(f'./data/texts/tst_{letter * 3}.pickle', tst_noted_phrases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
